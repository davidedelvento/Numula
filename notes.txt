11/25/21

At this point I have these tools:

1) Music21: Python library;
    defines a rich data structure for representing scores.
    These scores can be generated algorithmically,
    possibly using a compact textual notation,
    or parsed from files (musicXML or MIDI).
    They can be manipulated (volume/timing/articulation).
    They can be aggregated (e.g. chordify).
    They can be output in various forms (graphic score, test, MIDI)

2) MIDIUtils: Python library for generating MIDI files

3) PianoTeq: play MIDI files with piano sounds, to speakers or .WAV files

--------------
Some general goals:

1) "Prepared performance" with nuance,
of an existing piece (e.g. Berio or Bach).
I think it's best to use Music21 for this.
Many pieces are available on the web in various formats that Music21 can parse.
The textual notation makes it easy to enter new pieces.

What I need to write are functions that apply nuance to Stream objects.

Need to find out if Music21 distinguishes between notated time and performed time.

2) Algorithmic composition
Simple examples can be done directly using MIDIUtils,
but going forward I think it's better to use Music21.
- Can produce graphic scores
- Can use nuance operators as above
- Can use other Music21 features (pitch sets etc.)

3) Nuance analysis
If we have a score for a piece (say, MusicXML)
and the MIDI file for a human performance of the piece,
we could write a program to correlate the two and extract the nuance
(e.g. timing variation, horizontal/vertical dynamics, etc.)
This would be useful for defining nuance primitives, and it would make a good paper.

=====================

text notation

1/4 c4 d e f+ . a- +f+ 1/8 g {c e g}

1/4 or /4: duration of following notes

.: rest

c4: middle C

d: the D closest to previous pitch

f+: F sharp

+f: first F above previous pitch
++f: 2nd F above previous pitch

{c e g}: chord

{c e 1/2 g}: chord, g is half note

1/8 _: back up an eighth

NoteSet
    maintains current time, last vol, last dur
    NoteSet ns
    ns.append(n('a b c'))
    ns.insert(time, n('a b c'))
    ns.set_vol(), set_time(), set_dur()
    ns.get_time()

Nuance:
    have notion of "current time"
    time(x): set time
    dt(x): advane time

timing primitives:
Notes have
    "score time" - static
        use a slop factor for "simultaneous" because of roundoff
        score duration
    "performed time": seconds
        performed duration
    stages:
        1) tempo
            defines a continuous function from score to performed time
            seg(dt, func, params)
            func is a function that computes the integral of a tempo function
            e.g. linear(dt, tempo0, tempo1)(a,b)
                returns the integral of a line between a and b,
                where 0 <= a < b <= dt
            could also have exponential, etc.
            e.g.:
                ns.start()
                tseg(ns, 8/4, linear, [40, 60])
                tseg(ns, 8/4, linear, [60, 50])
            segment boundaries may not line up with note times,
            so some tricky computation is needed
            one approach:
                given the NoteSet, make another data structure which
                    has start and end records, each with a pointer to a Note.
                    Traverse this, computing performed times.
                    For start records, fill in Note.perf_time
                    For end records, fill in Note.perf_duration
            
        2) adjustments
            these change the time of some notes;
                thay may also add a delay to everything later
            pause
                whether silence is added
            roll
                neg offset per note
                specify whether it adds time
            agogic
            rubato
                specify a time map
                apply this to a group of tagged notes
                but don't change its overall duration
            random(dt, x)
                apply random shift
            these may also add pauses
        in 2 everything is in seconds

dynamics primitives
    volume is represented as 1..127
    adjustments to volume are represented as fractions (0..1), possibly > 1
    adjusted volumes are pegged at 1 and 127
        (print when this happens)

    stages:
        1) set base volume (e.g. crescendos)
            dyn(dt, v0, v1)
        2) adjust volume
            outer(dt, bottom, mid, top)
                "voice" notes that are highest/lowest
                e.g. outer(4, .8, .4, 1)
            metric(dt, pattern)
                apply metric emphases
            random(dt, x)
                apply random change

notes on outer:
    need to sort of simulate the piece to figure out it a note is highest and/or lowest
    cur_time = 0
    S = notes active at current time
    C = notes started at current time
    C is always a subset of S
    for each note N
        if n.time > cur_time+1e-4:
            is len(C):
                find min, max of pitches in S
                for each note in C
                    if pitch = min, tag as lowest
                    if pitch = max, tag as highest
            cur_time = N.time
            remove notes from S that end <= cur_time
            C = {N}
        else:
            add N to S
            add N to C

Note selection (for timing/vol adjustment, articulation)
    Notes have the following attributes:
        tags explicitly assigned
        highest/lowest
        number of simultaneous notes
    note selector:
        time range
        duration range
        required tags
        excluded tags
